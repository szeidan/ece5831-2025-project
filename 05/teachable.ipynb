{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d01b7c9f",
   "metadata": {},
   "source": [
    "# Let's Do Teachable "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3515a7e8",
   "metadata": {},
   "source": [
    "Written by Jaerock Kwon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176c696d",
   "metadata": {},
   "source": [
    "Let's a create Rock-Paper-Scissors game. Human vs. Computer!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dbdf93",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb08531",
   "metadata": {},
   "source": [
    "⚠️ Teachable model files are only compatiable with Tensorflow 2.12. There are version conflict issues in `pip` according to my experiments. I recommend that you use `conda install` instead of `pip` for this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4d79fb",
   "metadata": {},
   "source": [
    "### `teachable-2025` conda environment\n",
    "\n",
    "I prepared a `yaml` file (teachable-2025.yaml) for you to make things easier when you create a conda environment for this exercise. This yaml file has necessary information what versions of packages should be installed.\n",
    "- Create the `teachable-2025` conda environment using a `yaml` file\n",
    "```bsh\n",
    "conda env create -f teachable-2025.yaml\n",
    "```\n",
    "- Activate `teachable-2025`\n",
    "```bsh\n",
    "conda activate teachable-2025\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a29422",
   "metadata": {},
   "source": [
    "### Teachable Machine Image\n",
    "- Go to [Teachable Machine website](https://teachablemachine.withgoogle.com/train) and select the \"Image Project.\"\n",
    "- Select \"Standard image model\" because we will use our computer to run the trained model.\n",
    "- Create four classes: rock, paper, scissors1, and scissors2\n",
    "  - Add about 500 image samples to each class ()\n",
    "- Train model with the default option.\n",
    "- Use \"Export Model\" in \"Preview\" to export the trained model.\n",
    "  - There are three tabs. Choose \"Tensorflow\"\n",
    "  - Model conversion typoe: Keras\n",
    "  - Click the \"Download my model\" button\n",
    "    - This will download a zip file, `converted_keras.zip`\n",
    "    - Unzip this file. There are two files: `keras_model.h5` and `labels.txt`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b41738",
   "metadata": {},
   "source": [
    "### Locate Model and lable file\n",
    "I assume you created the `teachable` directory.\n",
    "- Create a directory, `model` inside the directory. The directory structure will be something like this: `nn/teachable-yyyy/model`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f59cae5",
   "metadata": {},
   "source": [
    "## Rock, Paper, Scissors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12adb303",
   "metadata": {},
   "source": [
    "Let's test the functionalities that are necessary to make this human vs. computer game!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d21de297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Sobhi\\anaconda3\\envs\\teachable-2025\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## import the libraries\n",
    "from keras.models import load_model  # TensorFlow is required for Keras to work\n",
    "from PIL import Image, ImageOps  # Install pillow instead of PIL\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f3d2162",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup\n",
    "# Disable scientific notation for clarity\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# The default image size for the model is 224x224\n",
    "size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b161b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the array of the right shape to feed into the keras model\n",
    "# The 'length' or number of images you can put into the array is\n",
    "# determined by the first position in the shape tuple, in this case 1\n",
    "data = np.ndarray(shape=(1, size[0], size[1], 3), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b269076",
   "metadata": {},
   "source": [
    "### Load model and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01fb4a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Sobhi\\anaconda3\\envs\\teachable-2025\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Sobhi\\anaconda3\\envs\\teachable-2025\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = load_model(\"model/keras_model.h5\", compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "832e8494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 rock\\n', '1 paper\\n', '2 scissors\\n']\n"
     ]
    }
   ],
   "source": [
    "# Load the labels\n",
    "class_names = open(\"model/labels.txt\", \"r\").readlines()\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120cfddd",
   "metadata": {},
   "source": [
    "### Test the prediction of the trained model with images\n",
    "\n",
    "- Create a directory, `test_images` for the testing\n",
    "- Find or create a test image for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40ffc172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with the path to your image\n",
    "image = Image.open(\"images/paper.jpg\").convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "468e1f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## resize and normalize the image\n",
    "\n",
    "# resizing the image to be at least 224x224 and then cropping from the center\n",
    "image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)\n",
    "\n",
    "# turn the image into a numpy array\n",
    "image_array = np.asarray(image)\n",
    "\n",
    "# Normalize the image\n",
    "normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n",
    "\n",
    "# Load the image into the array\n",
    "data[0] = normalized_image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3311252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "Class: rock\n",
      "Confidence Score: 0.50452685\n"
     ]
    }
   ],
   "source": [
    "## Test the trained model with images\n",
    "# Predicts the model\n",
    "prediction = model.predict(data)\n",
    "index = np.argmax(prediction)\n",
    "class_name = class_names[index]\n",
    "confidence_score = prediction[0][index]\n",
    "\n",
    "# Print prediction and confidence score\n",
    "print(\"Class:\", class_name[2:], end=\"\")\n",
    "print(\"Confidence Score:\", confidence_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38385064",
   "metadata": {},
   "source": [
    "### Test the model with the image frames from your camera\n",
    "\n",
    "`cv2.imshow()` might not work well in a Jupyter Notebook for live streaming. Let's capture 10 frames for testing the trained model. I will use `IPython.display` to updtate the output cell for testing. \n",
    "\n",
    "⚠️ Before running the next cell, get your hand be ready in front of the camera. Remember only 10 frames will be taken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7438140a",
   "metadata": {},
   "source": [
    "### Test Live Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a2da953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to exit the live camera view.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m         ret, frame = \u001b[43mcap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[32m     11\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFailed to grab frame\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print(\"Press 'q' to exit the live camera view.\")\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        # Show the live camera image\n",
    "        cv2.imshow('Live Camera', frame)\n",
    "\n",
    "        # Press 'q' to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff46875",
   "metadata": {},
   "source": [
    "### Let's combine the prediction and live camera\n",
    "\n",
    "⚠️ This Live Cam version might not work with you.\n",
    "\n",
    "⚠️ Your Live Cam window must have the focus. This means you have to click the window so that it can get your keyboard input. \n",
    "\n",
    "Press 'p' to predict or 'q' to exit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fd8f687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'p' to predict or 'q' to exit.\n",
      "Stopped by user.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print(\"Press 'p' to predict or 'q' to exit.\")\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        # Show the live camera image\n",
    "        cv2.imshow('Live Camera', frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('p'):  # Press 'p' to predict\n",
    "            resized_frame = cv2.resize(frame, size)  \n",
    "\n",
    "            # Prepare the image for prediction\n",
    "            image_array = np.asarray(resized_frame)\n",
    "            normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n",
    "            data[0] = normalized_image_array\n",
    "\n",
    "            # Predict\n",
    "            prediction = model.predict(data)\n",
    "            index = np.argmax(prediction)\n",
    "            class_name = class_names[index]\n",
    "            confidence_score = prediction[0][index]\n",
    "            print(f\"Class: {class_name[2:].strip()} | Confidence: {confidence_score:.4f}\")\n",
    "        elif key == ord('q'):  # Press 'q' to exit\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopped by user.\")\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d921f1f",
   "metadata": {},
   "source": [
    "It seems that all the basic functionalities are implemented and tested. Let's continue to make this game."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8c9349",
   "metadata": {},
   "source": [
    "### Add a few more functions to make the Human vs. Computer rock-paper-scissors game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3d53aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "## Function to get computer's random choice\n",
    "def computer_choice():\n",
    "    # 0: rock, 1: paper, 2: scissors (scissors1 or scissors2)\n",
    "    return random.choice([0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b62edd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to determine the winner\n",
    "def get_winner(computer_choice, user_choice):\n",
    "    # 0: rock, 1: paper, 2: scissors1, 3: scissors2\n",
    "    # Treat both 2 and 3 as scissors\n",
    "    def is_scissors(choice):\n",
    "        return choice == 2 or choice == 3\n",
    "\n",
    "    if computer_choice == user_choice or (is_scissors(computer_choice) and is_scissors(user_choice)):\n",
    "        return \"tie\"\n",
    "    elif (computer_choice == 0 and is_scissors(user_choice)) or \\\n",
    "         (computer_choice == 1 and computer_choice != user_choice and not is_scissors(user_choice) and user_choice == 0) or \\\n",
    "         (is_scissors(computer_choice) and user_choice == 1):\n",
    "        return \"computer\"\n",
    "    else:\n",
    "        return \"user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52c67438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'p' to play (ready your hand in front of the camera) or 'q' to exit.\n",
      "Stopped by user.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print(\"Press 'p' to play (ready your hand in front of the camera) or 'q' to exit.\")\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        # Show the live camera image\n",
    "        cv2.imshow('Live Camera', frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('p'):  # Press 'p' to predict\n",
    "\n",
    "            ## Get your choice\n",
    "            resized_frame = cv2.resize(frame, size)  \n",
    "\n",
    "            # Prepare the image for prediction\n",
    "            image_array = np.asarray(resized_frame)\n",
    "            normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n",
    "            data[0] = normalized_image_array\n",
    "\n",
    "            # Predict\n",
    "            prediction = model.predict(data, verbose=0)\n",
    "            index = np.argmax(prediction)\n",
    "            class_name = class_names[index]\n",
    "            confidence_score = prediction[0][index]\n",
    "            # print(f\"Class: {class_name[2:].strip()} | Confidence: {confidence_score:.4f}\")\n",
    "\n",
    "            your_choice = index\n",
    "            comp_choice = computer_choice()\n",
    "            winner = get_winner(comp_choice, your_choice)\n",
    "           \n",
    "            print(\"=\" * 30)\n",
    "            print(f\"Your choice: {class_names[your_choice][2:].strip()} | Computer's choice: {class_names[comp_choice][2:].strip()}\")\n",
    "            if winner == \"tie\":\n",
    "                print(\"It's a tie!\")\n",
    "            elif winner == \"user\":\n",
    "                print(\"You win!\")\n",
    "            else:\n",
    "                print(\"Computer wins!\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "        elif key == ord('q'):  # Press 'q' to exit\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopped by user.\")\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teachable-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
